{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv ## loads API keys\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "# from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain_community.vectorstores.chroma import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = PyPDFLoader(\"../grades_trim.pdf\")\n",
    "# loader = PyPDFLoader(\"../speech.pdf\")\n",
    "loader = PyPDFLoader(\"../econs.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=300)\n",
    "texts = text_splitter.split_documents(docs)\n",
    "\n",
    "## Initialize embedding model\n",
    "embed_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "# embed_model = HuggingFaceInstructEmbeddings(model_name=\"minishlab/potion-base-4M\")\n",
    "# embed_model = HuggingFaceEmbeddings(model_name=\"meta-llama/Meta-Llama-3-8B-Instruct\") #erroring out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=300)\n",
    "texts = text_splitter.split_documents(docs)\n",
    "\n",
    "# print(texts[1].page_content)\n",
    "# print(len(texts[1].page_content))\n",
    "# print(\"\\n\")\n",
    "# print(texts[2].page_content)\n",
    "# print(len(texts[2].page_content))\n",
    "# print(\"\\n\")\n",
    "# print(texts[3].page_content)\n",
    "# print(len(texts[3].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    embeds = embed_model.embed_documents([doc.page_content for doc in texts])\n",
    "    print(\"Vectors done!!!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in embed process: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vector store\n",
    "vector_store = Chroma(embedding_function=embed_model, persist_directory=\"data\")\n",
    "\n",
    "_ = vector_store.add_documents(documents=texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    test_query = \"what is the view on inflation?\"#\"what is the state of the economy\"\n",
    "    # test_query = \"what are the stress levels for the class?\"\n",
    "    # test_query = \"whats current liquidity landscape?\"\n",
    "    results = vector_store.search(query=test_query, search_type='similarity')\n",
    "\n",
    "    unique_results = OrderedDict()\n",
    "    for doc in results:\n",
    "        if doc.page_content not in unique_results:\n",
    "            unique_results[doc.page_content] = doc\n",
    "    \n",
    "    final_results = list(unique_results.values())[:3]\n",
    "    print(f\"Top query results:\\n{final_results[0].page_content}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during test query: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in final_results:\n",
    "    print(\"\\n\\tContent\\n\")\n",
    "    print(i.page_content)\n",
    "# print(final_results[1].page_content,\"\\n\")\n",
    "# print(final_results[2].page_content,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFaceHub\n",
    "\n",
    "hf_hub_llm = HuggingFaceHub(repo_id=\"google/flan-t5-xxl\", model_kwargs={\"temperature\":0.5, \"max_length\":512})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "# hf_hub_llm = HuggingFaceEndpoint(repo_id=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "#                                  temperature= 0.8, \n",
    "#                                  max_new_tokens= 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_huggingface.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# help(HuggingFaceEmbeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_huggingface.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# hf_hub_llm = HuggingFaceEmbeddings(repo_id=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "#                                            model_kwargs={\"temperature\": 0.8, \"max_new_tokens\": 1024}\n",
    "#                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(HuggingFaceEndpointEmbeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You are a highly educated economist and central bank policy assistant, your role is to accurately interpret queries on the economy \n",
    "and provide responses using the specialized database provided in the Context.\n",
    "Do not mention anything about charts or graphs. Provided your analysis as text response with facts from the data provided.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# prompt_template = \"\"\"\n",
    "# You are a highly educated class teacher and your role is to accurately interpret situation in the class based on the specialized database.\n",
    "\n",
    "# Query: {context}\n",
    "\n",
    "# Question: {question}\n",
    "\n",
    "# Answer:\n",
    "# \"\"\"\n",
    "\n",
    "custom_prompt = PromptTemplate(input_variables=[\"context\",\"question\"], template=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.retrieval_qa.base import RetrievalQA\n",
    "\n",
    "rag_chain = RetrievalQA.from_chain_type(llm=hf_hub_llm, \n",
    "                                        chain_type=\"stuff\", \n",
    "                                        retriever = vector_store.as_retriever(search_kwargs={'k': 3}),\n",
    "                                        chain_type_kwargs={\"prompt\": custom_prompt},return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(question):\n",
    "    result = rag_chain({\"query\": question})\n",
    "    response_text = result[\"result\"]\n",
    "    answer_start = response_text.find(\"Answer:\") + len(\"Answer:\")\n",
    "    answer = response_text[answer_start:].strip()\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rag_chain({\"query\": \"what is the view on inflation?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(get_response(\"whats current liquidity landscape?\"))\n",
    "# print(get_response(\"what are the stress levels for the class?\"))\n",
    "# print(get_response(\"what does the document say about union budget 2025-26?\"))\n",
    "print(get_response(\"what is the view on inflation?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bots_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
